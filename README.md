
# Qversity Project â€“ Cali 2025

A local data platform that implements a Lakehouse architecture (Bronze â†’ Silver â†’ Gold) using Docker Compose, Airflow, dbt, PostgreSQL, and FastAPI.

## ğŸ§  Overview

This project structures and transforms a messy mobile customer dataset into business-ready analytics using the **Medallion Architecture**:

- **Bronze Layer**: Raw data ingestion from a public JSON (S3), schema validation, and metadata enrichment.
- **Silver Layer**: Structured transformation into intermediate relational models.
- **Silver Cleaned**: Advanced data cleaning, quality validation, and normalization.
- **Gold Layer**: Final business analytics models â€“ customer segmentation, revenue analysis, ARPU by plan, device preferences, and more.

### ğŸ“‚ Business Insights

The folder [`/business_insights/`](./business_insights/) contains over **20 Markdown reports** covering:
- Device brand trends by country, operator, and plan
- Popular services and revenue-driving combinations
- Payment behavior and credit score correlation
- Customer acquisition and churn trends
- Demographic distributions (age, location, segment)
- Revenue breakdowns by region, plan, and customer type

Each insight is derived from a Gold-layer model and supports data-driven decision-making for telco strategy and optimization.

## ğŸ‘¤ Participant

- **Name**: Juan JosÃ© Angarita Yela
- **Email**: angaritayelaj@gmail.com
---

## ğŸ§± Architecture

```
/
â”œâ”€â”€ airflow/                   # Airflow DAGs and ETL logic
â”‚   â”œâ”€â”€ bronze/                # Ingestion, validation, raw load
â”‚   â”œâ”€â”€ dags/                  # Orchestration DAGs per layer
â”‚   â””â”€â”€ tests/                 # Integration tests for DAGs
â”œâ”€â”€ app/                       # FastAPI backend to expose Gold-layer models
â”‚   â”œâ”€â”€ api/routers/           # REST endpoints
â”‚   â”œâ”€â”€ core/                  # SQLAlchemy models and DB setup
â”‚   â”œâ”€â”€ db/                    # Repositories and logic
â”‚   â””â”€â”€ schemas/               # Pydantic schemas
â”œâ”€â”€ dbt/                       # dbt project with layered models
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ bronze/
â”‚       â”œâ”€â”€ silver/
â”‚       â”œâ”€â”€ silver_cleaned/
â”‚       â””â”€â”€ gold/
â”œâ”€â”€ business_insights/        # Markdown files with analytical summaries
â”œâ”€â”€ docker-compose.yml        # Container orchestration
â”œâ”€â”€ Dockerfile.airflow        # Custom Airflow image
â””â”€â”€ practices.txt             # Project logbook and notes
```

---

## ğŸš€ Quick Start

### Requirements

- Docker + Docker Compose
- At least 4GB of available RAM

### Setup

```bash
# Clone the repo
git clone <repo-url>
cd qversity-data-2025-Cali-JuanJoseAngaritaYela

# Start containers
docker compose up -d
```

---

## ğŸ”Œ Access Points

- **Airflow UI**: [http://localhost:8080](http://localhost:8080) (admin/admin)
- **FastAPI Docs**: [http://localhost:8000/docs](http://localhost:8000/docs)
- **PostgreSQL**: `localhost:5432` (user: `qversity-admin`, db: `qversity`)

---

## ğŸ›  Common Commands

### Airflow

```bash
docker compose logs -f airflow
docker compose exec airflow airflow dags trigger bronze_ingest_customers
```

### dbt

```bash
docker compose exec airflow bash
dbt run --select bronze
dbt run --select silver.*
dbt run --select silver_cleaned.*
dbt run --select gold.*
dbt test --select silver_cleaned.*
dbt test --select gold.*
dbt docs generate
dbt docs serve
```

### FastAPI

```bash
# Swagger UI available at:
http://localhost:8000/docs
```

---

## ğŸ§ª Development & Testing

### DAGs

1. Add new DAG in `airflow/dags/`
2. Airflow auto-detects it

### dbt Models

1. Create SQL files in `dbt/models/{layer}/`
2. Document and test them
3. Run with `dbt run`

### FastAPI Endpoints

1. Define SQLModel in `app/core/models.py`
2. Create Pydantic schema in `app/schemas`
3. Add route to `app/api/routers/gold.py`

### Tests

```bash
pytest airflow/tests/test_bronze_ingest_customers.py -vv
```

---

## ğŸ“ˆ Monitoring

```bash
docker compose logs -f airflow
docker compose logs -f dbt
docker compose logs -f postgres
docker compose ps
```

---

## ğŸ§¹ Cleanup

```bash
docker compose down
docker compose down -v      # âš ï¸ removes volumes
docker compose down --rmi all
```
