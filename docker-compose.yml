version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: qversity-admin
      POSTGRES_PASSWORD: qversity-admin
      POSTGRES_DB: qversity
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  airflow:
    image: apache/airflow:2.7.3-python3.11
    restart: on-failure
    depends_on:
      - postgres
    environment:
      DB_CONN_STR: "postgresql+psycopg2://qversity-admin:qversity-admin@postgres:5432/qversity"
      S3_URL: "https://qversity-raw-public-data.s3.amazonaws.com/mobile_customers_messy_dataset.json"
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      PYTHONPATH: /opt/airflow
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://qversity-admin:qversity-admin@postgres/qversity
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      _PIP_ADDITIONAL_REQUIREMENTS: dbt-core dbt-postgres pandas pytest great_expectations
    volumes:
      - ./airflow:/opt/airflow
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data
      - ./airflow/tests:/opt/airflow/tests
      - ./.env:/opt/airflow/.env
    ports:
      - "8080:8080"
    command: >
      bash -c "
      airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com &&
      airflow webserver & airflow scheduler
      "

  dbt:
    image: python:3.11
    volumes:
      - ./dbt:/dbt
      - ./data:/data
    working_dir: /dbt
    command: >
      bash -c "
      pip install dbt-core dbt-postgres &&
      sleep infinity
      "
    depends_on:
      - postgres
    environment:
      DBT_PROFILES_DIR: /dbt

volumes:
  postgres_data:
